<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Transcription App</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            text-align: center;
        }
        #transcription-results {
            display: flex;
            justify-content: space-between;
            margin-top: 20px;
        }
        .transcription-column {
            flex: 1;
            border: 1px solid #ddd;
            padding: 15px;
            margin: 0 10px;
            min-height: 200px;
            background-color: #f9f9f9;
            border-radius: 8px;
        }
        .transcription-column h3 {
            margin-bottom: 15px;
            color: #333;
            border-bottom: 2px solid #007bff;
            padding-bottom: 10px;
        }
        .transcription-column p {
            text-align: left;
            word-wrap: break-word;
        }
        .transcription-column small {
            color: #666;
            display: block;
            margin-top: 10px;
        }
        .button-container {
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 10px;
        }
        button {
            margin: 10px;
            padding: 10px 20px;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        #browser-support, #error-message {
            color: #666;
            margin-top: 10px;
        }
        #error-message {
            color: red;
        }
        #audio-player {
            margin-top: 20px;
            display: none;
        }
        #loading-indicator {
            display: none;
            color: #007bff;
            margin-top: 10px;
        }
    </style>
</head>
<body>
    <h1>Voice Transcription App</h1>
    <div class="button-container">
        <button id="startRecording">Start Recording</button>
        <button id="stopRecording" disabled>Stop Recording</button>
        <button id="transcribeRecording" disabled>Transcribe</button>
    </div>
    <div id="browser-support"></div>
    <div id="error-message"></div>
    <div id="loading-indicator">Transcribing... Please wait</div>
    
    <audio id="audio-player" controls></audio>
    
    <div id="transcription-results">
        <!-- Transcription results will be dynamically populated here -->
    </div>

    <!-- <script src="https://unpkg.com/@deepgram/sdk"></script> -->
    <script src="https://cdn.jsdelivr.net/npm/@deepgram/sdk"></script>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let audioBlob = null;
        let webSpeechRecognition = null;
        const resultsDiv = document.getElementById('transcription-results');
        const startButton = document.getElementById('startRecording');
        const stopButton = document.getElementById('stopRecording');
        const transcribeButton = document.getElementById('transcribeRecording');
        const browserSupportDiv = document.getElementById('browser-support');
        const errorMessageDiv = document.getElementById('error-message');
        const loadingIndicator = document.getElementById('loading-indicator');
        const audioPlayer = document.getElementById('audio-player');

        function getExtensionFromMimeType(mimeType) {
            const mapping = {
                'audio/wav': 'wav',
                'audio/webm': 'webm',
                'audio/ogg': 'ogg',
                'audio/mp4': 'mp4'
            };
            return mapping[mimeType] || 'webm'; // default fallback
        }

        // Determine best MIME type for recording
        function getSupportedMimeType() {
            const mimeTypes = [
                'audio/wav',
                'audio/webm',
                'audio/ogg',
                'audio/mp4'
            ];

            for (let mimeType of mimeTypes) {
                if (MediaRecorder.isTypeSupported(mimeType)) {
                    return mimeType;
                }
            }
            return null;
        }

        // Check browser speech recognition support
        function checkSpeechRecognitionSupport() {
            if ('SpeechRecognition' in window) {
                webSpeechRecognition = new SpeechRecognition();
                // browserSupportDiv.textContent = 'Web Speech API: Supported';
                return true;
            } else if ('webkitSpeechRecognition' in window) {
                webSpeechRecognition = new webkitSpeechRecognition();
                // browserSupportDiv.textContent = 'Web Speech API: Supported (Webkit)';
                return true;
            } else {
                browserSupportDiv.textContent = 'Web Speech API: Not Supported';
                return false;
            }
        }

        // Initialize on page load
        const supportedMimeType = getSupportedMimeType();
        checkSpeechRecognitionSupport();

        startButton.addEventListener('click', startRecording);
        stopButton.addEventListener('click', stopRecording);
        transcribeButton.addEventListener('click', transcribeRecording);

        async function startRecording() {
            // Reset previous state
            audioChunks = [];
            errorMessageDiv.textContent = '';
            
            try {
                // Check if a supported MIME type exists
                if (!supportedMimeType) {
                    throw new Error('No supported audio recording format found');
                }

                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                try {
                    mediaRecorder = new MediaRecorder(stream, { 
                        mimeType: supportedMimeType 
                    });
                } catch (recorderError) {
                    // Fallback to default configuration if specific MIME type fails
                    mediaRecorder = new MediaRecorder(stream);
                }

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = processRecording;
                mediaRecorder.start();

                startButton.disabled = true;
                stopButton.disabled = false;
                transcribeButton.disabled = true;
                audioPlayer.style.display = 'none';
                resultsDiv.innerHTML = '<p>Recording in progress...</p>';
            } catch (error) {
                console.error('Error accessing microphone:', error);
                errorMessageDiv.textContent = `Error: ${error.message}`;
                resultsDiv.innerHTML = `<p>Error: ${error.message}</p>`;
            }
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                startButton.disabled = false;
                stopButton.disabled = true;
            }
        }

        function processRecording() {
            if (audioChunks.length === 0) {
                errorMessageDiv.textContent = 'No audio recorded';
                return;
            }

            audioBlob = new Blob(audioChunks, { type: supportedMimeType });
            
            // Enable transcribe button
            transcribeButton.disabled = false;
            
            // Show audio player
            audioPlayer.src = URL.createObjectURL(audioBlob);
            audioPlayer.style.display = 'block';
        }

        async function transcribeRecording() {
            if (!audioBlob) {
                errorMessageDiv.textContent = 'No audio to transcribe';
                return;
            }

            // Show loading indicator
            loadingIndicator.style.display = 'block';
            resultsDiv.innerHTML = '';
            errorMessageDiv.textContent = '';

            // Prepare to collect results dynamically
            const transcriptionResults = {};
            const transcriptionServices = [
                transcribeWithDeepgram,
                transcribeWithWhisper,
                // transcribeWithWebSpeechAPI
            ];

            // Run transcriptions with immediate display
            transcriptionServices.forEach(async (transcribeMethod) => {
                try {
                    const result = await transcribeMethod(audioBlob);
                    transcriptionResults[result.service] = result;
                    updateTranscriptionDisplay(transcriptionResults);
                } catch (error) {
                    transcriptionResults[transcribeMethod.name] = {
                        service: transcribeMethod.name,
                        text: `Error: ${error.message}`,
                        confidence: 0
                    };
                    updateTranscriptionDisplay(transcriptionResults);
                }
            });

            // Hide loading indicator when done
            loadingIndicator.style.display = 'none';
        }

        function updateTranscriptionDisplay(results) {
            resultsDiv.innerHTML = Object.values(results).map(result => `
                <div class="transcription-column">
                    <h3>${result.service}</h3>
                    <p>${result.text}</p>
                    <small>Confidence: ${result.confidence ? result.confidence.toFixed(2) + '%' : 'N/A'}</small>
                </div>
            `).join('');
        }

        // Simulated API transcription methods
        async function transcribeWithDeepgram(audioBlob) {
            try {
                // Create a FormData object to send the audio file
                const formData = new FormData();
                const audioFile = new File([audioBlob], 'recording.webm', {
                    type: audioBlob.type
                });

                formData.append('audio', audioFile);

                // Send the audio to the backend
                const response = await fetch('https://audio.heymoon.co/transcribe', {
                    method: 'POST',
                    body: formData
                });

                if (!response.ok) {
                    throw new Error(`HTTP error! Status: ${response.status}`);
                }

                const result = await response.json();

                const transcript = result.results?.channels?.[0]?.alternatives?.[0];

                return {
                    service: 'Deepgram',
                    text: transcript?.transcript || 'No transcript available',
                    confidence: (transcript?.confidence || 0) * 100
                };
            } catch (error) {
                console.error("Transcription Error:", error);
                return {
                    service: 'Deepgram',
                    text: `Error: ${error.message}`,
                    confidence: 0
                };
            }
        }

        async function transcribeWithWhisper(audioBlob) {
            try {
                const fileExtension = getExtensionFromMimeType(audioBlob.type);
                // Create a FormData object to send the audio file
                const formData = new FormData();
                const audioFile = new File([audioBlob], `recording.${fileExtension}`, {
                    type: audioBlob.type
                });

                formData.append('audio', audioFile);

                // Send the audio to the backend
                const response = await fetch('https://audio.heymoon.co/whisper-transcribe', {
                    method: 'POST',
                    body: formData
                });

                if (!response.ok) {
                    throw new Error(`HTTP error! Status: ${response.status}`);
                }

                const result = await response.json();

                const transcript = result.text;

                return {
                    service: 'Whisper gpt-4o-transcribe',
                    text: transcript || 'No transcript available',
                    confidence: 0
                };
            } catch (error) {
                console.error("Transcription Error:", error);
                return {
                    service: 'Whisper gpt-4o-transcribe',
                    text: `Error: ${error.message}`,
                    confidence: 0
                };
            }
        }

        async function transcribeWithWebSpeechAPI(audioBlob=undefined) {
            return new Promise((resolve, reject) => {
                if (!webSpeechRecognition) {
                    resolve({
                        service: 'Web Speech API',
                        text: 'Speech Recognition not supported',
                        confidence: 0
                    });
                    return;
                }

                // Stop any existing recognition to prevent "already started" errors
                try {
                    webSpeechRecognition.stop();
                } catch (stopError) {
                    // Ignore stop errors
                }

                // Configure speech recognition
                webSpeechRecognition.continuous = false;
                webSpeechRecognition.interimResults = false;
                webSpeechRecognition.lang = 'en-US';

                // Reset any previous results
                let finalTranscript = '';
                let confidence = 0;

                // Create a timeout to handle cases where recognition doesn't trigger
                const recognitionTimeout = setTimeout(() => {
                    try {
                        webSpeechRecognition.stop();
                    } catch (stopError) {
                        // Ignore stop errors
                    }
                    resolve({
                        service: 'Web Speech API',
                        text: 'No speech detected or recognition failed.',
                        confidence: 0
                    });
                }, 5000);

                // Listen for recognition results
                webSpeechRecognition.onresult = (event) => {
                    clearTimeout(recognitionTimeout);
                    for (let i = event.resultIndex; i < event.results.length; ++i) {
                        if (event.results[i].isFinal) {
                            finalTranscript += event.results[i][0].transcript;
                            confidence = event.results[i][0].confidence;
                        }
                    }

                    if (finalTranscript) {
                        resolve({
                            service: 'Web Speech API',
                            text: finalTranscript,
                            confidence: confidence * 100
                        });
                    }
                };

                // Handle errors
                webSpeechRecognition.onerror = (event) => {
                    clearTimeout(recognitionTimeout);
                    try {
                        webSpeechRecognition.stop();
                    } catch (stopError) {
                        // Ignore stop errors
                    }
                    resolve({
                        service: 'Web Speech API',
                        text: `Error: ${event.error}`,
                        confidence: 0
                    });
                };

                // Attempt to start recognition
                try {
                    webSpeechRecognition.start();
                } catch (error) {
                    clearTimeout(recognitionTimeout);
                    resolve({
                        service: 'Web Speech API',
                        text: `Error: ${error.message}`,
                        confidence: 0
                    });
                }
            });
        }
    </script>
</body>
</html>
